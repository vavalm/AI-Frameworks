{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Ateliers: Technologies de l'intelligence Artificielle](https://github.com/wikistat/AI-Frameworks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<a href=\"http://www.insa-toulouse.fr/\" ><img src=\"http://www.math.univ-toulouse.fr/~besse/Wikistat/Images/logo-insa.jpg\" style=\"float:left; max-width: 120px; display: inline\" alt=\"INSA\"/></a> \n",
    "<a href=\"http://wikistat.fr/\" ><img src=\"http://www.math.univ-toulouse.fr/~besse/Wikistat/Images/wikistat.jpg\" width=400, style=\"max-width: 150px; display: inline\"  alt=\"Wikistat\"/></a>\n",
    "<a href=\"http://www.math.univ-toulouse.fr/\" ><img src=\"http://www.math.univ-toulouse.fr/~besse/Wikistat/Images/logo_imt.jpg\" width=400,  style=\"float:right;  display: inline\" alt=\"IMT\"/> </a>\n",
    "    \n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traitement Naturel du Langage (NLP) : Catégorisation de Produits Cdiscount\n",
    "\n",
    "Il s'agit d'une version simplifiée du concours proposé par Cdiscount et paru sur le site [datascience.net](https://www.datascience.net/fr/challenge). Les données d'apprentissage sont accessibles sur demande auprès de Cdiscount mais les solutions de l'échantillon test du concours ne sont pas et ne seront pas rendues publiques. Un échantillon test est donc construit pour l'usage de ce tutoriel.  L'objectif est de prévoir la catégorie d'un produit à partir de son descriptif (*text mining*). Seule la catégorie principale (1er niveau, 47 classes) est prédite au lieu des trois niveaux demandés dans le concours. L'objectif est plutôt de comparer les performances des méthodes et technologies en fonction de la taille de la base d'apprentissage ainsi que d'illustrer sur un exemple complexe le prétraitement de données textuelles. \n",
    "\n",
    "Le jeux de données complet (15M produits) permet un test en vrai grandeur du **passage à l'échelle volume** des phases de préparation (*munging*), vectorisation (hashage, TF-IDF) et d'apprentissage en fonction de la technologie utilisée.\n",
    "\n",
    "La synthèse des résultats obtenus est développée par [Besse et al. 2016](https://hal.archives-ouvertes.fr/hal-01350099) (section 5)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partie 1-3 : Modèle d'apprentissage statistiques.\n",
    "\n",
    "Dans le calepin numéro 2, nous avons créés 2x7 matrices de features correspondant au mêmes échantillons d'apprentissage et de validation des données textuelles de description d'objet de Cdiscount.  Ces matrices ont été crées avec les méthodes suivantes. \n",
    "\n",
    "1. `Count_Vectorizer`. `No hashing`.\n",
    "2. `Count_Vectorizer`. `Hashing = 300`.\n",
    "3. `TFIDF_vectorizer`. `No hashing`. \n",
    "4. `TFIDF_vectorizer`. `Hashing = 300`.\n",
    "5. `Word2Vec`. `CBOW`\n",
    "6. `Word2Vec`. `Skip-Gram`\n",
    "7. `Word2Vec`. `Pre-trained`\n",
    "\n",
    "Nous allons maintenant étudiés les performances d'algorithmes de *machine learning* (`Regression logistique`, `Forêts aléatoire`, `Perceptron multicouche`) sur ces différents features "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importation des librairies utilisées\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sc\n",
    "import pickle\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "sb.set_style(\"whitegrid\")\n",
    "\n",
    "DATA_DIR = \"data/features\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Téléchargement des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Téléchargement des variables réponses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = pd.read_csv(\"data/cdiscount_train_subset.csv\").fillna(\"\")[\"Categorie1\"]\n",
    "Y_valid = pd.read_csv(\"data/cdiscount_valid.csv\").fillna(\"\")[\"Categorie1\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Création d'un dictionnaire contenant les chemins ou des différents objets où sont stockés les matrices de features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_path_dic = {}\n",
    "\n",
    "parameters = [[\"count_no_hashing\", None, \"count\"],\n",
    "              [\"count_300\", 300, \"count\"],\n",
    "              [\"tfidf_no_hashing\", None, \"tfidf\"],\n",
    "              [\"tfidf_300\",300, \"tfidf\"]]\n",
    "for name, nb_hash, vectorizer in parameters:\n",
    "        x_train_path = DATA_DIR +\"/vec_train_nb_hash_\" + str(nb_hash) + \"_vectorizer_\" + str(vectorizer)+\".npz\"\n",
    "        x_valid_path = DATA_DIR +\"/vec_valid_nb_hash_\" + str(nb_hash) + \"_vectorizer_\" + str(vectorizer)+\".npz\"\n",
    "        dic = {\"x_train_path\" : x_train_path, \"x_valid_path\" : x_valid_path, \"load\" : \"npz\"}\n",
    "        features_path_dic.update({name : dic})\n",
    " \n",
    "parametersw2v = [[\"word2vec_cbow\",\"cbow\"],\n",
    "                 [\"word2vec_sg\",\"sg\"],\n",
    "                 [\"word2vec_online\",\"online\"]]\n",
    "for name, mtype in parametersw2v:\n",
    "        x_train_path = DATA_DIR +\"/embedded_train_\" + mtype+\".npy\"\n",
    "        x_valid_path = DATA_DIR +\"/embedded_valid_\" + mtype+\".npy\"\n",
    "        dic = {\"x_train_path\" : x_train_path, \"x_valid_path\" : x_valid_path, \"load\" : \"npy\"}\n",
    "        features_path_dic.update({name : dic})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Logistique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apprentissage\n",
    "\n",
    "Le code suivant peut être très long. Vous pouvez dans un premier temps exécutez directement la cellule suivante ou les résultats de l'execution de cette cellules sont disponibles. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "metadata_list_lr = []\n",
    "\n",
    "param_grid = {\"C\" : [10,1,0.1]}\n",
    "#param_grid = {\"C\" : [1]}\n",
    "\n",
    "for name, dic in features_path_dic.items():\n",
    "    \n",
    "    x_train_path = dic[\"x_train_path\"]\n",
    "    x_valid_path = dic[\"x_valid_path\"]\n",
    "    load = dic[\"load\"]\n",
    "    \n",
    "    print(\"Load features : \" + name)\n",
    "    if load == \"npz\":\n",
    "        X_train = sc.sparse.load_npz(x_train_path)\n",
    "        X_valid = sc.sparse.load_npz(x_valid_path)\n",
    "    else : \n",
    "        X_train = np.load(x_train_path)\n",
    "        X_valid = np.load(x_valid_path)\n",
    "    \n",
    "    print(\"start Learning :\" + name)\n",
    "    ts = time.time()\n",
    "    gs = GridSearchCV(LogisticRegression(), param_grid=param_grid, verbose=15)\n",
    "    gs.fit(X_train,Y_train.values)\n",
    "    te=time.time()\n",
    "    t_learning = te-ts\n",
    "    \n",
    "    print(\"start prediction :\" + name)\n",
    "    ts = time.time()\n",
    "    score_train=gs.score(X_train,Y_train)\n",
    "    score_valid=gs.score(X_valid,Y_valid)\n",
    "    te=time.time()\n",
    "    t_predict = te-ts\n",
    "    \n",
    "    metadata = {\"name\":name, \"learning_time\" : t_learning, \"predict_time\":t_predict, \"score_train\": score_train, \"score_valid\": score_valid}\n",
    "    metadata_list_lr.append(metadata)\n",
    "pickle.dump(metadata_list_lr, open(\"data/metadata_lr_part13.pkl\",\"wb\"))       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploitation des résultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "metadata_list_lr = pickle.load(open(\"data/metadata_lr_part13.pkl\",\"rb\"))       \n",
    "metadata_list_lr_sorted = sorted(metadata_list_lr, key = lambda x : x[\"name\"])\n",
    "xlabelticks = [metadata[\"name\"] for metadata in metadata_list_lr_sorted]\n",
    "\n",
    "fig = plt.figure(figsize=(20,6))\n",
    "key_plot = [key for key in metadata_list_lr[0].keys() if key !=\"name\"]\n",
    "for iplot, key in enumerate(key_plot):\n",
    "    ax = fig.add_subplot(1,4,iplot+1)\n",
    "    for i,metadata in enumerate(metadata_list_lr_sorted):\n",
    "        if key==\"learning_time\":\n",
    "            scale=60\n",
    "            ylabel=\"Time(mn)\"\n",
    "        elif key==\"predict_time\":\n",
    "            scale=1\n",
    "            ylabel=\"Time(seconds)\"\n",
    "        else:\n",
    "            scale=0.01\n",
    "            ylabel = 'Accuracy (pcy)'\n",
    "            \n",
    "        ax.scatter(i,metadata[key]/scale, s=100)\n",
    "        ax.text(i,metadata[key]/scale,\"%.2f\"%(metadata[key]/scale), ha=\"left\", va=\"top\")\n",
    "    ax.set_xticks(np.arange(7))\n",
    "    ax.set_xticklabels(xlabelticks, rotation=45, fontsize=15, ha=\"right\")\n",
    "    ax.set_title(key, fontsize=20)\n",
    "    ax.set_ylabel(ylabel, fontsize=15)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q** Comment expliquer le long de temps d'apprentissage de la regression logistique sur les modèles issues de Word2Vec?\n",
    "\n",
    "**Q** Comment expliquer la différence de qualité d'apprentissage en fonction du hashing ?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_list_rf = []\n",
    "\n",
    "param_grid = {\"n_estimators\" : [100,500]}\n",
    "\n",
    "for name, dic in features_path_dic.items():\n",
    "    \n",
    "    x_train_path = dic[\"x_train_path\"]\n",
    "    x_valid_path = dic[\"x_valid_path\"]\n",
    "    load = dic[\"load\"]\n",
    "    \n",
    "    print(\"Load features : \" + name)\n",
    "    if load == \"npz\":\n",
    "        X_train = sc.sparse.load_npz(x_train_path)\n",
    "        X_valid = sc.sparse.load_npz(x_valid_path)\n",
    "    else : \n",
    "        X_train = np.load(x_train_path)\n",
    "        X_valid = np.load(x_valid_path)\n",
    "    \n",
    "    print(\"start Learning :\" + name)\n",
    "    ts = time.time()\n",
    "    gs = GridSearchCV(RandomForestClassifier(), param_grid=param_grid, verbose=15)\n",
    "    gs.fit(X_train,Y_train.values)\n",
    "    te=time.time()\n",
    "    t_learning = te-ts\n",
    "    \n",
    "    print(\"start prediction :\" + name)\n",
    "    ts = time.time()\n",
    "    score_train=gs.score(X_train,Y_train)\n",
    "    score_valid=gs.score(X_valid,Y_valid)\n",
    "    te=time.time()\n",
    "    t_predict = te-ts\n",
    "    \n",
    "    metadata = {\"name\":name, \"learning_time\" : t_learning, \"predict_time\":t_predict, \"score_train\": score_train, \"score_valid\": score_valid}\n",
    "    metadata_list_rf.append(metadata)\n",
    "pickle.dump(metadata_list_rf, open(\"data/metadata_rf_part13.pkl\",\"wb\"))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_list_rf = pickle.load(open(\"data/metadata_rf_part13.pkl\",\"rb\"))       \n",
    "metadata_list_rf_sorted = sorted(metadata_list_rf, key = lambda x : x[\"name\"])\n",
    "xlabelticks = [metadata[\"name\"] for metadata in metadata_list_rf_sorted]\n",
    "\n",
    "fig = plt.figure(figsize=(20,6))\n",
    "key_plot = [key for key in metadata_list_rf[0].keys() if key !=\"name\"]\n",
    "for iplot, key in enumerate(key_plot):\n",
    "    ax = fig.add_subplot(1,4,iplot+1)\n",
    "    for i,metadata in enumerate(metadata_list_rf_sorted):\n",
    "        if key==\"learning_time\":\n",
    "            scale=60\n",
    "            ylabel=\"Time(mn)\"\n",
    "        elif key==\"predict_time\":\n",
    "            scale=1\n",
    "            ylabel=\"Time(seconds)\"\n",
    "        else:\n",
    "            scale=0.01\n",
    "            ylabel = 'Accuracy (pcy)'\n",
    "            \n",
    "        ax.scatter(i,metadata[key]/scale, s=100)\n",
    "        ax.text(i,metadata[key]/scale,\"%.2f\"%(metadata[key]/scale), ha=\"left\", va=\"top\")\n",
    "    ax.set_xticks(np.arange(7))\n",
    "    ax.set_xticklabels(xlabelticks, rotation=45, fontsize=15, ha=\"right\")\n",
    "    ax.set_title(key, fontsize=20)\n",
    "    ax.set_ylabel(ylabel, fontsize=15)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_list_mlp = []\n",
    "\n",
    "param_grid = {\"hidden_layer_sizes\" : [32,64,128, 256]}\n",
    "\n",
    "for name, dic in features_path_dic.items():\n",
    "    \n",
    "    x_train_path = dic[\"x_train_path\"]\n",
    "    x_valid_path = dic[\"x_valid_path\"]\n",
    "    load = dic[\"load\"]\n",
    "    \n",
    "    print(\"Load features : \" + name)\n",
    "    if load == \"npz\":\n",
    "        X_train = sc.sparse.load_npz(x_train_path)\n",
    "        X_valid = sc.sparse.load_npz(x_valid_path)\n",
    "    else : \n",
    "        X_train = np.load(x_train_path)\n",
    "        X_valid = np.load(x_valid_path)\n",
    "    \n",
    "    print(\"start Learning :\" + name)\n",
    "    ts = time.time()\n",
    "    gs = GridSearchCV(MLPClassifier(learning_rate = \"adaptive\", ), param_grid=param_grid, verbose=15)\n",
    "    gs.fit(X_train,Y_train.values)\n",
    "    te=time.time()\n",
    "    t_learning = te-ts\n",
    "    \n",
    "    print(\"start prediction :\" + name)\n",
    "    ts = time.time()\n",
    "    score_train=gs.score(X_train,Y_train)\n",
    "    score_valid=gs.score(X_valid,Y_valid)\n",
    "    te=time.time()\n",
    "    t_predict = te-ts\n",
    "    \n",
    "    metadata = {\"name\":name, \"learning_time\" : t_learning, \"predict_time\":t_predict, \"score_train\": score_train, \"score_valid\": score_valid}\n",
    "    metadata_list_mlp.append(metadata)\n",
    "pickle.dump(metadata_list_mlp, open(\"data/metadata_mlp_part13.pkl\",\"wb\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_list_mlp = pickle.load(open(\"data/metadata_mlp_part13.pkl\",\"rb\"))       \n",
    "metadata_list_mlp_sorted = sorted(metadata_list_mlp, key = lambda x : x[\"name\"])\n",
    "xlabelticks = [metadata[\"name\"] for metadata in metadata_list_mlp_sorted]\n",
    "\n",
    "fig = plt.figure(figsize=(20,6))\n",
    "key_plot = [key for key in metadata_list_mlp[0].keys() if key !=\"name\"]\n",
    "for iplot, key in enumerate(key_plot):\n",
    "    ax = fig.add_subplot(1,4,iplot+1)\n",
    "    for i,metadata in enumerate(metadata_list_mlp_sorted):\n",
    "        if key==\"learning_time\":\n",
    "            scale=60\n",
    "            ylabel=\"Time(mn)\"\n",
    "        elif key==\"predict_time\":\n",
    "            scale=1\n",
    "            ylabel=\"Time(seconds)\"\n",
    "        else:\n",
    "            scale=0.01\n",
    "            ylabel = 'Accuracy (pcy)'\n",
    "            \n",
    "        ax.scatter(i,metadata[key]/scale, s=100)\n",
    "        ax.text(i,metadata[key]/scale,\"%.2f\"%(metadata[key]/scale), ha=\"left\", va=\"top\")\n",
    "    ax.set_xticks(np.arange(7))\n",
    "    ax.set_xticklabels(xlabelticks, rotation=45, fontsize=15, ha=\"right\")\n",
    "    ax.set_title(key, fontsize=20)\n",
    "    ax.set_ylabel(ylabel, fontsize=15)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
