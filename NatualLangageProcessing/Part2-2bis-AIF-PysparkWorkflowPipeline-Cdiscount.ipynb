{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Ateliers: Technologies des données massives](https://github.com/wikistat/Ateliers-Big-Data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<a href=\"http://www.insa-toulouse.fr/\" ><img src=\"http://www.math.univ-toulouse.fr/~besse/Wikistat/Images/logo-insa.jpg\" style=\"float:left; max-width: 120px; display: inline\" alt=\"INSA\"/></a> \n",
    "<a href=\"http://wikistat.fr/\" ><img src=\"http://www.math.univ-toulouse.fr/~besse/Wikistat/Images/wikistat.jpg\" width=400, style=\"max-width: 150px; display: inline\"  alt=\"Wikistat\"/></a>\n",
    "<a href=\"http://www.math.univ-toulouse.fr/\" ><img src=\"http://www.math.univ-toulouse.fr/~besse/Wikistat/Images/logo_imt.jpg\" width=400,  style=\"float:right;  display: inline\" alt=\"IMT\"/> </a>\n",
    "    \n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traitement Naturel du Langage (NLP) : Catégorisation de Produits Cdiscount\n",
    "\n",
    "Il s'agit d'une version simplifiée du concours proposé par Cdiscount et paru sur le site [datascience.net](https://www.datascience.net/fr/challenge). Les données d'apprentissage sont accessibles sur demande auprès de Cdiscount mais les solutions de l'échantillon test du concours ne sont pas et ne seront pas rendues publiques. Un échantillon test est donc construit pour l'usage de ce tutoriel.  L'objectif est de prévoir la catégorie d'un produit à partir de son descriptif (*text mining*). Seule la catégorie principale (1er niveau, 47 classes) est prédite au lieu des trois niveaux demandés dans le concours. L'objectif est plutôt de comparer les performances des méthodes et technologies en fonction de la taille de la base d'apprentissage ainsi que d'illustrer sur un exemple complexe le prétraitement de données textuelles. \n",
    "\n",
    "Le jeux de données complet (15M produits) permet un test en vrai grandeur du **passage à l'échelle volume** des phases de préparation (*munging*), vectorisation (hashage, TF-IDF) et d'apprentissage en fonction de la technologie utilisée.\n",
    "\n",
    "La synthèse des résultats obtenus est développée par [Besse et al. 2016](https://hal.archives-ouvertes.fr/hal-01350099) (section 5)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partie 2-2 Catégorisation des Produits Cdiscount avec [SparkML](https://spark.apache.org/docs/latest/ml-guide.html) de <a href=\"http://spark.apache.org/\"><img src=\"http://spark.apache.org/images/spark-logo-trademark.png\" style=\"max-width: 100px; display: inline\" alt=\"Spark\"/></a>  et utilisation de Pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le contenu de ce calepin est sensiblement identique au calepin précédent : Part2-2-AIF-PysparkWorkflow-Cdiscount.ipynb \n",
    "Dans ce dernier, le résultat de chaque étape était détaillé afin d'aider a la compréhension de celles-ci.  \n",
    "\n",
    "Dans ce calepin, nous utilisons la fonction **Pipeline** de la librairie spark-ML afin de créer un modèle qui inclut directement toutes les étapes, du nettoyage de texte jusqu'a l'apprentissage d'un modèle de regression logistique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://insa-10826.insa-toulouse.fr:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.3.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=pyspark-shell>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Importation des packages génériques et ceux \n",
    "# des librairie ML et MLlib\n",
    "##Nettoyage\n",
    "import nltk\n",
    "import re\n",
    "##Liste\n",
    "from numpy import array\n",
    "##Temps\n",
    "import time\n",
    "##Row and Vector\n",
    "from pyspark.sql import Row\n",
    "from pyspark.ml.linalg import Vectors\n",
    "##Hashage et vectorisation\n",
    "from pyspark.ml.feature import HashingTF\n",
    "from pyspark.ml.feature import IDF\n",
    "##Regression logistique\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "##Decision Tree\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "##Random Forest\n",
    "from pyspark.ml.classification import RandomForestClassifier \n",
    "##Pour la création des DataFrames\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.ml import Pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Lecture des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Categorie1='INFORMATIQUE', Categorie2='CONNECTIQUE - ALIMENTATION', Categorie3='BATTERIE', Description='Batterie Acer Aspire One 751H-52Yr - Li-Ion 11.1V 5200mAh, 54Wh Noir, compatible batterie… Voir la présentation', Libelle='Batterie Acer Aspire One 751H-52Yr', Marque='AUCUNE'),\n",
       " Row(Categorie1='TELEPHONIE - GPS', Categorie2='ACCESSOIRE TELEPHONE', Categorie3='COQUE - BUMPER - FACADE TELEPHONE', Description='Coque rigide Bleu lagon pour ALCATEL OT / 6033 motif Drapeau Liberia + 3 Films - Coque rigide Ultra Fine Bleu lagon ORIGINALE de MUZZANO au motif Drapeau Liberia pour ALCATEL … Voir la présentation', Libelle='Coque rigide Bleu lagon pour ALCATEL OT / 6033 …', Marque='MUZZANO')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sqlContext = SQLContext(sc)\n",
    "RowDF = sqlContext.read.format('com.databricks.spark.csv').options(header='true', inferschema='true').load('data/cdiscount_train.csv')\n",
    "RowDF.take(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extraction sous-échantillon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataTrain : size = 799962, DataTest : size = 190050\n"
     ]
    }
   ],
   "source": [
    "# Taux de sous-échantillonnage des données pour tester le programme de préparation\n",
    "# sur un petit jeu de données\n",
    "taux_donnees=[0.80,0.19,0.01]\n",
    "dataTrain, DataTest, data_drop = RowDF.randomSplit(taux_donnees)\n",
    "n_train = dataTrain.count()\n",
    "n_test= DataTest.count()\n",
    "print(\"DataTrain : size = %d, DataTest : size = %d\"%(n_train, n_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Création du pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création d'un Transformer pour l'étape de stemming.\n",
    "\n",
    "Dans le calepin précédent, nous avons définie une fonction stemmer à partir de la librairie *nltk*. Pour que celle-ci puisse être utilisé dans un **Pipeline ML**, nous devons en faire un objet **transformers**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark import keyword_only\n",
    "from pyspark.ml import Transformer\n",
    "from pyspark.ml.param.shared import HasInputCol, HasOutputCol, Param\n",
    "from pyspark.sql.functions import udf, col\n",
    "from pyspark.sql.types import ArrayType, StringType\n",
    "\n",
    "class MyNltkStemmer(Transformer, HasInputCol, HasOutputCol):\n",
    "\n",
    "    @keyword_only\n",
    "    def __init__(self, inputCol=None, outputCol=None):\n",
    "        super(MyNltkStemmer, self).__init__()\n",
    "        kwargs = self._input_kwargs\n",
    "        self.setParams(**kwargs)\n",
    "\n",
    "    @keyword_only\n",
    "    def setParams(self, inputCol=None, outputCol=None):\n",
    "        kwargs = self._input_kwargs\n",
    "        return self._set(**kwargs)\n",
    "\n",
    "    def _transform(self, dataset):\n",
    "        STEMMER = nltk.stem.SnowballStemmer('french')\n",
    "        def clean_text(tokens):\n",
    "            tokens_stem = [ STEMMER.stem(token) for token in tokens]\n",
    "            return tokens_stem\n",
    "        udfCleanText =  udf(lambda lt : clean_text(lt), ArrayType(StringType()))\n",
    "        out_col = self.getOutputCol()\n",
    "        in_col = dataset[self.getInputCol()]\n",
    "        return dataset.withColumn(out_col, udfCleanText(in_col))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Définition des différentes étapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from pyspark.sql.types import ArrayType\n",
    "from pyspark.ml.feature import RegexTokenizer, StopWordsRemover\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "# liste des mots à supprimer\n",
    "STOPWORDS = set(nltk.corpus.stopwords.words('french'))\n",
    "# Fonction tokenizer qui permet de remplacer un long texte par une liste de mot\n",
    "regexTokenizer = RegexTokenizer(inputCol=\"Description\", outputCol=\"tokenizedDescr\", pattern=\"[^a-z_]\",\n",
    "                                minTokenLength=3, gaps=True)\n",
    "\n",
    "#V1\n",
    "# Fonction StopWordsRemover qui permet de supprimer des mots\n",
    "#remover = StopWordsRemover(inputCol=\"tokenizedDescr\", outputCol=\"cleanDescr\", stopWords = list(STOPWORDS))\n",
    "\n",
    "#V2\n",
    "# Fonction StopWordsRemover qui permet de supprimer des mots\n",
    "remover = StopWordsRemover(inputCol=\"tokenizedDescr\", outputCol=\"stopTokenizedDescr\", stopWords = list(STOPWORDS))\n",
    "# Stemmer \n",
    "stemmer = MyNltkStemmer(inputCol=\"stopTokenizedDescr\", outputCol=\"cleanDescr\")\n",
    "\n",
    "# Indexer\n",
    "indexer = StringIndexer(inputCol=\"Categorie1\", outputCol=\"categoryIndex\")\n",
    "\n",
    "# Hasing\n",
    "hashing_tf = HashingTF(inputCol=\"cleanDescr\", outputCol='tf', numFeatures=10000)\n",
    "\n",
    "# Inverse Document Frequency\n",
    "idf = IDF(inputCol=hashing_tf.getOutputCol(), outputCol=\"tfidf\")\n",
    "\n",
    "#Logistic Regression\n",
    "lr = LogisticRegression(maxIter=100, regParam=0.01, fitIntercept=False, tol=0.0001,\n",
    "            family = \"multinomial\", elasticNetParam=0.0, featuresCol=\"tfidf\", labelCol=\"categoryIndex\") #0 for L2 penalty, 1 for L1 penalty\n",
    "\n",
    "# Creation du pipeline\n",
    "pipeline = Pipeline(stages=[regexTokenizer, remover, stemmer, indexer, hashing_tf, idf, lr ])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimation du pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le paramètre de pénalisation (lasso) est pris par défaut sans optimisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_start = time.time()\n",
    "# On applique toutes les étapes sur la DataFrame d'apprentissage.\n",
    "model = pipeline.fit(dataTrain)\n",
    "time_end=time.time()\n",
    "time_lrm=(time_end - time_start)\n",
    "print(\"LR prend %d s pour un echantillon d'apprentissage de taille : n = %d\" %(time_lrm, n_train)) # (104s avec taux=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Estimation de l'erreur sur l'échantillon test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionsDF = model.transform(DataTest)\n",
    "labelsAndPredictions = predictionsDF.select(\"categoryIndex\",\"prediction\").collect()\n",
    "nb_good_prediction = sum([r[0]==r[1] for r in labelsAndPredictions])\n",
    "testErr = 1-nb_good_prediction/n_test\n",
    "print('Test Error = , pour un echantillon test de taille n = %d' + str(testErr)) # (0.08 avec taux =1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taille M| Temps | Erreur\n",
    "-------|-------|--------\n",
    "1.131  | 786   | 0.94"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python (PySpark)",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
